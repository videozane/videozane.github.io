{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e727dc",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc91e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from opencv-python) (2.2.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b20bd",
   "metadata": {},
   "source": [
    "## Part 0.1: Calibrating Your Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a82206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create ArUco dictionary and detector parameters (4x4 tags)\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "aruco_params = cv2.aruco.DetectorParameters()\n",
    "\n",
    "def import_images(path):\n",
    "    images = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.lower().endswith('.jpg'):\n",
    "            img_path = os.path.join(path, filename)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is not None:\n",
    "                images.append(image)\n",
    "    return images\n",
    "\n",
    "def get_points(images):\n",
    "    object_points = [] # world space 3D\n",
    "    image_points = [] # pixel space 2D\n",
    "\n",
    "    single_tag_object_points = np.array([\n",
    "        [0.0, 0.0, 0.0],\n",
    "        [0.02, 0.0, 0.0],\n",
    "        [0.02, 0.02, 0.0],\n",
    "        [0.0, 0.02, 0.0]\n",
    "    ], dtype=np.float32)\n",
    "    image_size = None\n",
    "\n",
    "    for image in images:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if image_size is None:\n",
    "            image_size = gray.shape[::-1] # w, h\n",
    "\n",
    "        # Detect ArUco markers in an image\n",
    "        # Returns: corners (list of numpy arrays), ids (numpy array)\n",
    "        corners, ids, _ = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=aruco_params)\n",
    "\n",
    "        # Check if any markers were detected\n",
    "        if ids is not None:\n",
    "            # Process the detected corners\n",
    "            # corners: list of length N (number of detected tags)\n",
    "            #   - each element is a numpy array of shape (1, 4, 2) containing the 4 corner coordinates (x, y)\n",
    "            # ids: numpy array of shape (N, 1) containing the tag IDs for each detected marker\n",
    "            # Example: if 3 tags detected, corners will be a list of 3 arrays, ids will be shape (3, 1)\n",
    "            obj_points_for_this_image = np.empty((0, 3), dtype=np.float32)\n",
    "            img_points_for_this_image = np.empty((0, 2), dtype=np.float32)\n",
    "\n",
    "            for i in range(len(ids)):\n",
    "                obj_points_for_this_image = np.vstack((obj_points_for_this_image, single_tag_object_points))\n",
    "                img_points_for_this_image = np.vstack((img_points_for_this_image, corners[i].reshape(4, 2)))\n",
    "                \n",
    "            object_points.append(obj_points_for_this_image)\n",
    "            image_points.append(img_points_for_this_image)\n",
    "            cv2.aruco.drawDetectedMarkers(image, corners, ids)\n",
    "            cv2.imshow('Detections', image)\n",
    "            cv2.waitKey(1500)\n",
    "        else:\n",
    "            # No tags detected in this image, skip it\n",
    "            pass\n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "    return object_points, image_points, image_size\n",
    "\n",
    "images = import_images(\"./aruco_images\")\n",
    "object_points, image_points, image_size = get_points(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56afbb2e",
   "metadata": {},
   "source": [
    "## Calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        object_points, \n",
    "        image_points, \n",
    "        image_size,  # w, h\n",
    "        None, \n",
    "        None\n",
    "    )\n",
    "\n",
    "if ret:\n",
    "    print(\"\\nCamera Matrix (K):\")\n",
    "    print(camera_matrix)\n",
    "    \n",
    "    print(\"\\nDistortion Coefficients:\")\n",
    "    print(dist_coeffs)\n",
    "    np.savez('./calibrate_results/camera_calibration.npz', camera_matrix=camera_matrix, dist_coeffs=dist_coeffs)\n",
    "        \n",
    "else:\n",
    "    print(\"\\nCalibration Failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db779cf",
   "metadata": {},
   "source": [
    "## Part 0.2: Capturing a 3D Object Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cbd18b",
   "metadata": {},
   "source": [
    "Placed in ./object_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b853093",
   "metadata": {},
   "source": [
    "## Part 0.3: Estimating Camera Pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841d378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "CALIBRATION_DIR = './aruco_images'\n",
    "OBJECT_SCAN_DIR = './object_images' \n",
    "TAG_SIZE_METERS = 0.02\n",
    "FRUSTUM_SCALE = 0.02\n",
    "CALIBRATION_FILE = './calibrate_results/camera_calibration.npz'\n",
    "\n",
    "if os.path.exists(CALIBRATION_FILE):\n",
    "    print(f\"Loading calibration\")\n",
    "    calibration_data = np.load(CALIBRATION_FILE)\n",
    "    camera_matrix = calibration_data['camera_matrix']\n",
    "    dist_coeffs = calibration_data['dist_coeffs']\n",
    "else:\n",
    "    print(\"No calibration. need Part 0.1\")\n",
    "\n",
    "object_scan_images = import_images(OBJECT_SCAN_DIR)\n",
    "if not object_scan_images:\n",
    "    print(\"Need Part 0.2\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Starting pose estimation for {len(object_scan_images)} images...\")\n",
    "\n",
    "single_tag_object_points = np.array([\n",
    "    [0.0, 0.0, 0.0],\n",
    "    [TAG_SIZE_METERS, 0.0, 0.0],\n",
    "    [TAG_SIZE_METERS, TAG_SIZE_METERS, 0.0],\n",
    "    [0.0, TAG_SIZE_METERS, 0.0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "valid_c2w_matrices = []\n",
    "valid_images = []\n",
    "\n",
    "H, W = 0, 0\n",
    "\n",
    "for img in object_scan_images:\n",
    "    if H == 0:\n",
    "        H, W = img.shape[:2]\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect markers\n",
    "    corners, ids, _ = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=aruco_params)\n",
    "\n",
    "    if ids is not None and len(ids) == 1:\n",
    "        imagePoints = corners[0].reshape(4, 2)\n",
    "        \n",
    "        success, rvec, tvec = cv2.solvePnP(\n",
    "            objectPoints=single_tag_object_points, \n",
    "            imagePoints=imagePoints, \n",
    "            cameraMatrix=camera_matrix, \n",
    "            distCoeffs=dist_coeffs\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            R, _ = cv2.Rodrigues(rvec)\n",
    "            \n",
    "            w2c_matrix = np.eye(4)\n",
    "            w2c_matrix[:3, :3] = R\n",
    "            w2c_matrix[:3, 3] = tvec.ravel()\n",
    "            \n",
    "            c2w_matrix = np.linalg.inv(w2c_matrix)\n",
    "            \n",
    "            valid_c2w_matrices.append(c2w_matrix)\n",
    "            valid_images.append(img)\n",
    "            \n",
    "        else:\n",
    "            print(f\"solvePnP failed\")\n",
    "    else:\n",
    "        print(f\"No tag\")\n",
    "\n",
    "print(f\"\\nPose done. {len(valid_c2w_matrices)} valid poses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9fdc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'viser'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mviser\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m server \u001b[38;5;241m=\u001b[39m viser\u001b[38;5;241m.\u001b[39mViserServer(share\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'viser'"
     ]
    }
   ],
   "source": [
    "import viser\n",
    "import numpy as np\n",
    "\n",
    "server = viser.ViserServer(share=True)\n",
    "\n",
    "focal = camera_matrix[0, 0]\n",
    "fov_y = 2 * np.arctan2(H / 2, focal)\n",
    "aspect_ratio = W / H\n",
    "\n",
    "for i in range(len(valid_c2w_matrices)):\n",
    "    c2w = valid_c2w_matrices[i]\n",
    "    img = valid_images[i]\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    server.scene.add_camera_frustum(\n",
    "        f\"/cameras/{i}\",\n",
    "        fov=fov_y,\n",
    "        aspect=aspect_ratio,\n",
    "        scale=FRUSTUM_SCALE,\n",
    "        wxyz=viser.transforms.SO3.from_matrix(c2w[:3, :3]).wxyz,\n",
    "        position=c2w[:3, 3],\n",
    "        image=img_rgb\n",
    "    )\n",
    "\n",
    "print(\"Visualization running. Open the URL in your browser.\")\n",
    "while True:\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef6fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
